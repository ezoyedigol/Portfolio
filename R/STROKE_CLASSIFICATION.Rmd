---
title: "Stroke_Classification"
output:
  word_document: default
  pdf_document: default
  html_document:
    df_print: paged
date: "2024-03-22"
---
Task: In this task, we are working with a dataset called "stroke_classification". The main aim of this dataset is to assess the risk of stroke in patients.
Problem: The problem we are tackling is a classification problem. We aim to predict whether patients are at risk of having a stroke or not based on their features.

# Loading the packages
```{r}
library(MLDataR)
library(caret)
```

#Loading the stroke_classification dataset
```{r}
data(stroke_classification)
```

Features: The dataset contains various features that describe the demographic and clinical characteristics of the patients. These features include:
•	Gender: Male, Female, or Other
•	Age: Age of the patient
•	Hypertension: Whether the patient has hypertension or not (0: No, 1: Yes)
•	Heart Disease: Whether the patient has heart disease or not (0: No, 1: Yes)
•	Work Related Stress: Whether the patient experiences work-related stress or not (0: No, 1: Yes)
•	Urban Residence: Whether the patient lives in an urban area or not (0: No, 1: Yes)
•	Avg Glucose Level: Average glucose level in the patient's blood
•	BMI: Body Mass Index of the patient
•	Smokes: Whether the patient smokes or not (0: No, 1: Yes)
Target: The target variable we are predicting is called "stroke". It indicates whether the patient had a stroke or not. (0: No stroke, 1: Stroke)

# Showing the first few rows of the dataset
```{r}
head(stroke_classification)
```
1.	Number of Instances: The dataset contains a total of 5110 instances or rows.

2.	Data Type: Most of the variables are numeric, except for the "gender" variable, which is categorical.

# Structure of the dataset
```{r}
str(stroke_classification)
```
# Checking for missing values
```{r}
sum(is.na(stroke_classification))

colSums(is.na(stroke_classification))
```
Missing Values: The dataset contains missing values, particularly in the "bmi" column, which have been imputed using the median value of the BMI variable.
# Fill in missing values (bmi variable) 
```{r}
median_bmi <- median(stroke_classification$bmi, na.rm = TRUE)
stroke_classification$bmi[is.na(stroke_classification$bmi)] <- median_bmi
```

# Split the dataset into training and test sets
```{r}
set.seed(123) # Set a seed to control randomness
train_index <- sample(1:nrow(stroke_classification), round(nrow(stroke_classification)*0.80)) # Indices for the training set
train_data <- stroke_classification[train_index, ] # Training set
test_data <- stroke_classification[-train_index, ] # Test set
```

Training a Logistic Regression Model:
To train a logistic regression model, we utilized the glm() function in R, specifying the family argument as "binomial" since we're dealing with binary classification.
# Train the logistic regression model
```{r}
lr_model <- glm(stroke ~ ., data = train_data, family = "binomial")
lr_model

```
# Show the coefficients of the trained model
```{r}
summary(lr_model)

```
# Make predictions on the test set
```{r}
predictions <- predict(lr_model, newdata = test_data, type = "response")
```
# Convert predictions to classes (0 or 1)
```{r}
predicted_classes <- ifelse(predictions > 0.5, 1, 0)
```

# Calculating True Positive (TP), False Positive (FP), True Negative (TN), False Negative (FN) counts
```{r}
TP <- sum(predicted_classes[test_data$stroke == 1] == 1)
FP <- sum(predicted_classes[test_data$stroke == 0] == 1)
TN <- sum(predicted_classes[test_data$stroke == 0] == 0)
FN <- sum(predicted_classes[test_data$stroke == 1] == 0)
```

# Calculating recall, precision, specificity, and accuracy
```{r}
recall <- TP / (TP + FN)
precision <- TP / (TP + FP)
specificity <- TN / (TN + FP)
accuracy <- (TN + TP) / (TP + FN + TN + FP)
recall
precision
specificity
accuracy

```
Reporting Performance Metrics:
We evaluated the performance of the trained logistic regression model using the following three metrics:
1.	Accuracy: Accuracy measures the overall correctness of the model's predictions.
•	Formula: (TP + TN) / (TP + TN + FP + FN)
•	Result: Our model achieved an accuracy of 99.90%.
2.	Precision: Precision measures the proportion of true positive predictions among all positive predictions made by the model.
•	Formula: TP / (TP + FP)
•	Result: The precision of our model is 98.25%.
3.	Recall (Sensitivity): Recall, also known as sensitivity, measures the proportion of actual positives that were correctly identified by the model.
•	Formula: TP / (TP + FN)
•	Result: The recall of our model is 100%.

# Calculating confusion matrix
```{r}
cm <- confusionMatrix(table(ifelse(test_data$stroke == 1, "1", "0"), 
                            as.factor(predicted_classes)), positive = "1")

```

# Calculating Brier score
```{r}
brier_score <- mean((as.numeric(predicted_classes) - test_data$stroke) ^ 2)
brier_score
```
Performance Evaluation Using Brier Score:
The Brier score is a proper scoring rule that measures the accuracy of probabilistic predictions.
•	Calculation: We computed the Brier score using the mean squared difference between the predicted probabilities and the actual outcomes.
•	Result: The Brier score of our model is approximately 0.00098.
These performance metrics collectively provide insights into the effectiveness of our logistic regression model in predicting stroke risk. The high accuracy, precision, recall, and low Brier score indicate that the model performs well in classifying patients with and without strokes.
